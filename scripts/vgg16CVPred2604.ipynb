{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_class = 2\n",
    "ROWS, COLS = 224, 224\n",
    "BATCHSIZE = 128\n",
    "SEAL_CLASSES = ['NoS', 'seal']\n",
    "nb_perClass = int(BATCHSIZE / len(SEAL_CLASSES))\n",
    "TRAIN_DIR = '../darknet/seals/JPEGImagesBlk'\n",
    "TEST_DIR = '../darknet/seals/JPEGImagesTest'\n",
    "# Data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "# Fine-tune Example\n",
    "rfcnCV = pd.read_pickle('../coords/rfcnCV.pkl')\n",
    "rfcnCV.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "70016/70000 [==============================] - 4190s - loss: 0.0899 - acc: 0.9680 - val_loss: 0.0851 - val_acc: 0.9683\n",
      "Epoch 2/3\n",
      "70016/70000 [==============================] - 4186s - loss: 0.0818 - acc: 0.9714 - val_loss: 0.0812 - val_acc: 0.9701\n",
      "Epoch 3/3\n",
      "70016/70000 [==============================] - 4184s - loss: 0.0725 - acc: 0.9733 - val_loss: 0.0748 - val_acc: 0.9729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f95fc3a5150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make our validation set\n",
    "folds = [rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 != 0,\n",
    "        rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 == 0]\n",
    "\n",
    "for fold in range(2):\n",
    "    train_df = rfcnCV[~folds[fold]]\n",
    "    valid_df = rfcnCV[folds[fold]]\n",
    "\n",
    "    # validation_data (valid_x,valid_y)\n",
    "    df_1 = valid_df\n",
    "    l = valid_df.groupby('seal').size()\n",
    "    nb_NoF_valid = math.ceil(l.sum()/10)\n",
    "    valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "    valid_y = np.zeros((valid_df.shape[0], len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "    i = 0\n",
    "    for index,row in valid_df.iterrows():\n",
    "        row = row.tolist()\n",
    "        image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "        seal = row[6]\n",
    "        bbox = row[2:6]\n",
    "        cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "        x = np.asarray(cropped, dtype=K.floatx())\n",
    "        x = preprocess_input(x)\n",
    "        valid_x[i] = x\n",
    "        valid_y[i,seal] = 1\n",
    "        i += 1\n",
    "    valid_x = valid_x.transpose(0, 3, 1, 2)\n",
    "    valid_x.shape\n",
    "\n",
    "    # Load our model\n",
    "    nb_epoch = 2\n",
    "    samples_per_epoch = 50000\n",
    "    model = vgg_std16_model(ROWS, COLS, channel, num_class)\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    model.fit_generator(train_generator(train_datagen, train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch, #50000,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    for layer in model.layers[10:]:\n",
    "        layer.trainable = True\n",
    "    model.optimizer.lr = 1e-4\n",
    "    nb_epoch = 3\n",
    "    model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    # Test preds save\n",
    "    test_preds = model.predict_generator(test_generator(valid_df), val_samples=valid_df.shape[0])\n",
    "    df = pd.concat([valid_df, pd.DataFrame(test_preds,  columns=['predNoSeal', 'predSeal'])], axis=1)\n",
    "    df.to_pickle('../coords/vggCVPreds2604_fold' + str(fold+1) + '.pkl')\n",
    "    df[['img', 'predSeal']].to_csv('../coords/vggCVPreds2604_fold' + str(fold+1) + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
