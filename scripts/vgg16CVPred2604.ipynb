{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_class = 2\n",
    "ROWS, COLS = 224, 224\n",
    "BATCHSIZE = 64\n",
    "SEAL_CLASSES = ['NoS', 'seal']\n",
    "nb_perClass = int(BATCHSIZE / len(SEAL_CLASSES))\n",
    "TRAIN_DIR = '../darknet/seals/JPEGImagesBlk'\n",
    "TEST_DIR = '../darknet/seals/JPEGImagesTest'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>seal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.894</td>\n",
       "      <td>364.95</td>\n",
       "      <td>295.10</td>\n",
       "      <td>464.95</td>\n",
       "      <td>395.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.893</td>\n",
       "      <td>228.20</td>\n",
       "      <td>376.30</td>\n",
       "      <td>328.20</td>\n",
       "      <td>476.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.720</td>\n",
       "      <td>407.75</td>\n",
       "      <td>409.95</td>\n",
       "      <td>507.75</td>\n",
       "      <td>509.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img  proba      x0      y0      x1      y1  seal\n",
       "0  228_54  0.894  364.95  295.10  464.95  395.10     0\n",
       "1  228_54  0.893  228.20  376.30  328.20  476.30     0\n",
       "2  228_54  0.720  407.75  409.95  507.75  509.95     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "# Fine-tune Example\n",
    "rfcnCV = pd.read_pickle('../coords/rfcnCV.pkl')\n",
    "rfcnCV.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146060, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make our validation set\n",
    "folds = [rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 != 0,\n",
    "        rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 == 0]\n",
    "rfcnCV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2\n",
      "Part ... A\n",
      "0\n",
      "300\n",
      "600\n",
      "900\n",
      "1200\n",
      "Part ... B\n",
      "Part ... C\n",
      "Epoch 1/2\n",
      "50048/50000 [==============================] - 2653s - loss: 0.6821 - acc: 0.6624 - val_loss: 0.2907 - val_acc: 0.8893\n",
      "Epoch 2/2\n",
      "50048/50000 [==============================] - 2690s - loss: 0.2089 - acc: 0.9212 - val_loss: 0.2277 - val_acc: 0.9067\n",
      "Part ... D\n",
      "Epoch 1/3\n",
      "50048/50000 [==============================] - 2694s - loss: 0.1553 - acc: 0.9434 - val_loss: 0.1420 - val_acc: 0.9420\n",
      "Epoch 2/3\n",
      "50048/50000 [==============================] - 2693s - loss: 0.1329 - acc: 0.9526 - val_loss: 0.1227 - val_acc: 0.9540\n",
      "Epoch 3/3\n",
      "50048/50000 [==============================] - 2694s - loss: 0.1134 - acc: 0.9589 - val_loss: 0.1185 - val_acc: 0.9507\n",
      "Part ... E\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for fold in range(2):\n",
    "    print \"Fold: \" + str(fold+1)\n",
    "    train_df = rfcnCV[~folds[fold]]\n",
    "    test_df = rfcnCV[folds[fold]]\n",
    "    valid_df = test_df[:1500]\n",
    "    \n",
    "    # validation_data (valid_x,valid_y)\n",
    "    print \"Part ... A\"\n",
    "    df_1 = valid_df\n",
    "    l = valid_df.groupby('seal').size()\n",
    "    nb_NoF_valid = math.ceil(l.sum()/10)\n",
    "    valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "    valid_y = np.zeros((valid_df.shape[0], len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "    i = 0\n",
    "    for index,row in valid_df.iterrows():\n",
    "        if index % 300 == 0 : print index\n",
    "        row = row.tolist()\n",
    "        image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "        seal = row[6]\n",
    "        bbox = row[2:6]\n",
    "        cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "        x = np.asarray(cropped, dtype=K.floatx())\n",
    "        x = preprocess_input(x)\n",
    "        valid_x[i] = x\n",
    "        valid_y[i,seal] = 1\n",
    "        i += 1\n",
    "    valid_x = valid_x.transpose(0, 3, 1, 2)\n",
    "    valid_x.shape\n",
    "\n",
    "    # Load our model\n",
    "    print \"Part ... B\"\n",
    "    nb_epoch = 2\n",
    "    samples_per_epoch = 50000\n",
    "    model = vgg_std16_model(ROWS, COLS, channel, num_class)\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    print \"Part ... C\"\n",
    "    model.fit_generator(train_generator(train_datagen, train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch, #50000,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    for layer in model.layers[10:]:\n",
    "        layer.trainable = True\n",
    "    model.optimizer.lr = 1e-4\n",
    "    nb_epoch = 3\n",
    "    print \"Part ... D\"\n",
    "    model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    # Test preds save\n",
    "    print \"Part ... E\"\n",
    "    test_preds = model.predict_generator(testcv_generator(test_df), val_samples=test_df.shape[0])\n",
    "    df = pd.concat([test_df.reset_index(drop=True), pd.DataFrame(test_preds,  columns=['predNoSeal', 'predSeal'])], axis=1)\n",
    "    df.to_pickle('../coords/vggCVPreds2604_fold' + str(fold+1) + '.pkl')\n",
    "    df[['img', 'predSeal']].to_csv('../coords/vggCVPreds2604_fold' + str(fold+1) + '.csv', index=False)\n",
    "    \n",
    "    # Clean up\n",
    "    del model, train_df, test_df, valid_df, valid_x, df_1\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
