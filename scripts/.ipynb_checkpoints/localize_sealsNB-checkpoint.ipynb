{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc, math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "from scipy.misc import imsave\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dropout, Dense, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './checkpoints/checkpoint01/'\n",
    "make_train = False\n",
    "validate_train = False\n",
    "cutoff = 0.7\n",
    "block_size = 544\n",
    "img_w = 4896 # width\n",
    "img_h = 3264 # height\n",
    "boundaries = [100,80,70,70,40]\n",
    "colors = ['red', 'blue', 'green', 'yellow', 'pink']\n",
    "check_border = 20\n",
    "SEAL_CLASSES = ['NoS', 'Seal', 'Other']\n",
    "ROWS = 100\n",
    "COLS = 100\n",
    "BATCHSIZE = 16\n",
    "TRAIN_DIR = '../darknet/seals/JPEGImagesBlk'\n",
    "nb_perClass = int(BATCHSIZE / len(SEAL_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def preprocess_input(x):\n",
    "    #resnet50 image preprocessing\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    x[:, :, 0] -= 100\n",
    "    x[:, :, 1] -= 115\n",
    "    x[:, :, 2] -= 124\n",
    "    return x\n",
    "\n",
    "def create_rect5(row):\n",
    "    if is_seal:\n",
    "        return plt.Rectangle((row['x0'], row['y0']), row['w'], row['h'], color='red', fill=False, lw=2)\n",
    "    else:\n",
    "        return plt.Rectangle((row['x0'], row['y0']), row['w'], row['h'], color='red', fill=False, lw=4)\n",
    "\n",
    "def load_img(path, bbox, target_size=None):\n",
    "    img = Image.open(path)\n",
    "    img = img.convert('RGB')\n",
    "    cropped = img.crop((bbox[0],bbox[1],bbox[2],bbox[3]))\n",
    "    if target_size:\n",
    "        cropped = cropped.resize((target_size[1], target_size[0]))\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the Xtrain files\n",
    "if make_train:\n",
    "    rfcnCVfold2 = pd.read_csv(\"../coords/comp4_30000_det_test_seals_fold2.txt\",\\\n",
    "                        delimiter = \" \", header=None, names=['img', 'proba', 'x0', 'y0', 'x1', 'y1'])\n",
    "    rfcnCVfold1 = pd.read_csv(\"../coords/comp4_30000_det_test_seals_fold1.txt\",\\\n",
    "                        delimiter = \" \", header=None, names=['img', 'proba', 'x0', 'y0', 'x1', 'y1'])\n",
    "    rfcnCVfold1['img'] = rfcnCVfold1['img'].str.replace('/home/ubuntu/noaa/darknet/seals/JPEGImagesBlk/', '')\n",
    "    rfcnCV = pd.concat([rfcnCVfold2, rfcnCVfold1])\n",
    "    rfcnCV = rfcnCV[rfcnCV['proba']>cutoff]\n",
    "    rfcnCV = rfcnCV[(rfcnCV['x1']-rfcnCV['x0'])<150]\n",
    "    rfcnCV = rfcnCV[(rfcnCV['y1']-rfcnCV['y0'])<150]\n",
    "    del rfcnCVfold1, rfcnCVfold2\n",
    "    gc.collect()\n",
    "\n",
    "    # Get the ground truth labels\n",
    "    coords = pd.read_csv(\"../feat/coords_meta.csv\")\n",
    "    train_meta = pd.read_csv(\"../feat/train_meta.csv\", usecols = ['id', 'height', 'width', 'all_diff'])#,\\\n",
    "    train_meta.columns = ['id', 'img_height', 'img_width', 'all_diff']\n",
    "    coords = pd.merge(coords, train_meta, on='id', how='inner')\n",
    "    coords['block_width'] = coords['width'].apply(lambda x: x*img_w).div(coords['img_width'], axis=0).apply(int)%block_size\n",
    "    coords['block_height'] = coords['height'].apply(lambda x: x*img_h).div(coords['img_height'], axis=0).apply(int)%block_size\n",
    "    coords['block'] = coords['width'].apply(lambda x: x*img_w).div(coords['img_width'], axis=0).apply(int).apply(lambda x: x/block_size).apply(str)+\\\n",
    "                        coords['height'].apply(lambda x: x*img_h).div(coords['img_height'], axis=0).apply(int).apply(lambda x: x/block_size).apply(str)\n",
    "\n",
    "    # For each row, check if there is a seal in the block\n",
    "    def is_seal(row):\n",
    "        row_id, row_block = row['img'].split('_')\n",
    "        seal = ((coords['id']==int(row_id)) & \\\n",
    "                    (coords['block'] == row_block) & \\\n",
    "                    (coords['block_width']>(int(row['x0'])-check_border)) & \\\n",
    "                    (coords['block_width']<(int(row['x1'])+check_border)) & \\\n",
    "                    (coords['block_height']>(int(row['y0'])-check_border)) & \\\n",
    "                    (coords['block_height']<(int(row['y1'])+check_border))).any()\n",
    "        return int(seal)\n",
    "\n",
    "    from tqdm import tqdm, tqdm_pandas\n",
    "    tqdm_pandas(tqdm())\n",
    "\n",
    "    rfcnCV['seal'] = rfcnCV.progress_apply(is_seal, axis=1)\n",
    "    rfcnCV = rfcnCV.reset_index(drop=True)\n",
    "    rfcnCV['h_diff'] = ROWS - (rfcnCV['y1'] -rfcnCV['y0'])\n",
    "    rfcnCV['w_diff'] = COLS - (rfcnCV['x1'] -rfcnCV['x0'])\n",
    "    rfcnCV[rfcnCV['h_diff']<0]['h_diff'] = 0\n",
    "    rfcnCV[rfcnCV['w_diff']<0]['w_diff'] = 0\n",
    "    rfcnCV['x0'] = rfcnCV['x0'] - rfcnCV['w_diff']/2\n",
    "    rfcnCV['x1'] = rfcnCV['x1'] + rfcnCV['w_diff']/2\n",
    "    rfcnCV['y0'] = rfcnCV['y0'] - rfcnCV['h_diff']/2\n",
    "    rfcnCV['y1'] = rfcnCV['y1'] + rfcnCV['h_diff']/2\n",
    "    rfcnCV[['x0', 'x1']] = rfcnCV[['x0', 'x1']].add(np.where(rfcnCV['x0']<0, rfcnCV['x0'].abs(), 0), axis = 0 )\n",
    "    rfcnCV[['y0', 'y1']] = rfcnCV[['y0', 'y1']].add(np.where(rfcnCV['y0']<0, rfcnCV['y0'].abs(), 0), axis = 0 )\n",
    "    rfcnCV[['x0', 'x1']] = rfcnCV[['x0', 'x1']].subtract(np.where(rfcnCV['x1']>block_size, (rfcnCV['x1']-block_size).abs(), 0), axis = 0 )\n",
    "    rfcnCV[['y0', 'y1']] = rfcnCV[['y0', 'y1']].subtract(np.where(rfcnCV['y1']>block_size, (rfcnCV['y1']-block_size).abs(), 0), axis = 0 )\n",
    "    rfcnCV.drop(['h_diff', 'w_diff'], axis=1, inplace=True)\n",
    "    rfcnCV.to_pickle('../coords/rfcnCV.pkl')\n",
    "else:\n",
    "    rfcnCV = pd.read_pickle('../coords/rfcnCV.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>seal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.894</td>\n",
       "      <td>364.95</td>\n",
       "      <td>295.10</td>\n",
       "      <td>464.95</td>\n",
       "      <td>395.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.893</td>\n",
       "      <td>228.20</td>\n",
       "      <td>376.30</td>\n",
       "      <td>328.20</td>\n",
       "      <td>476.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.720</td>\n",
       "      <td>407.75</td>\n",
       "      <td>409.95</td>\n",
       "      <td>507.75</td>\n",
       "      <td>509.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854_02</td>\n",
       "      <td>0.954</td>\n",
       "      <td>129.45</td>\n",
       "      <td>104.10</td>\n",
       "      <td>229.45</td>\n",
       "      <td>204.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>854_02</td>\n",
       "      <td>0.923</td>\n",
       "      <td>336.45</td>\n",
       "      <td>5.30</td>\n",
       "      <td>436.45</td>\n",
       "      <td>105.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img  proba      x0      y0      x1      y1  seal\n",
       "0  228_54  0.894  364.95  295.10  464.95  395.10     0\n",
       "1  228_54  0.893  228.20  376.30  328.20  476.30     0\n",
       "2  228_54  0.720  407.75  409.95  507.75  509.95     0\n",
       "3  854_02  0.954  129.45  104.10  229.45  204.10     0\n",
       "4  854_02  0.923  336.45    5.30  436.45  105.30     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rfcnCV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets validate the train file\n",
    "if validate_train:\n",
    "    cond = rfcnCV.img.str.contains('1000')\n",
    "    for img_name in rfcnCV[cond].img.unique():\n",
    "        img = imread('../darknet/seals/JPEGImagesBlk/%s.jpg'%(img_name))\n",
    "        bbox = rfcnCV[rfcnCV['img'] == img_name]\n",
    "        bbox['w'] = bbox['x1'] - bbox['x0']\n",
    "        bbox['h'] = bbox['y1'] - bbox['y0']\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(img)\n",
    "        for c, row in bbox.iterrows():\n",
    "            plt.gca().add_patch(plt.Rectangle((row['x0'], row['y0']), row['w'],\\\n",
    "            row['h'], color='red', fill=False, lw=1+(2*row['seal'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby(['seal'], as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "            seal = row[6]\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "            #plt.figure(figsize=(2,2))\n",
    "            #plt.imshow(cropped) \n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            # batch_y[i,SEAL_CLASSES.index(seal)] = 1\n",
    "            batch_y[i,seal] = 1\n",
    "            i += 1\n",
    "        # return (batch_x, batch_y)\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X, y = train_generator(datagen=train_datagen, df=train_df)\n",
    "#type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets make our validation set\n",
    "CVsplit = rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 40 == 0\n",
    "train_df = rfcnCV[~CVsplit]\n",
    "valid_df = rfcnCV[CVsplit]\n",
    "\n",
    "# validation_data (valid_x,valid_y)\n",
    "df_1 = valid_df\n",
    "l = valid_df.groupby('seal').size()\n",
    "nb_NoF_valid = math.ceil(l.sum()/10)\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "    seal = row[6]\n",
    "    bbox = row[2:6]\n",
    "    cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "    x = np.asarray(cropped, dtype=K.floatx())\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    #valid_y[i,SEAL_CLASSES.index(seal)] = 1\n",
    "    valid_y[i,seal] = 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #rotation_range=180,\n",
    "    #shear_range=0.2,\n",
    "    #zoom_range=0.1,\n",
    "    #width_shift_range=0.1,\n",
    "    #height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "model_checkpoint = ModelCheckpoint(filepath=CHECKPOINT_DIR+'weights.{epoch:03d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "learningrate_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start modelling\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, init='glorot_normal')(x)\n",
    "x = LeakyReLU(alpha=0.33)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(SEAL_CLASSES), init='glorot_normal', activation='softmax')(x)\n",
    "model = Model(input=base_model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# compile the model \n",
    "optimizer = Adam(lr=1e-4)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_per_epoch = 2000\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(train_generator(datagen=train_datagen, df=train_df),\n",
    "                    samples_per_epoch=samples_per_epoch,\n",
    "                    nb_epoch=12, verbose=0,\n",
    "                    callbacks=[early_stopping, learningrate_schedule],  # , tensorboard, model_checkpoint,\n",
    "                    validation_data=(valid_x,valid_y), nb_worker=3, pickle_safe=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
