{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc, math\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_class = 2\n",
    "ROWS, COLS = 224, 224\n",
    "BATCHSIZE = 64\n",
    "SEAL_CLASSES = ['seal_0', 'seal_1', 'seal_2',  'seal_3_4', 'seal_5_9', 'seal_10']\n",
    "nb_perClass = int(BATCHSIZE / len(SEAL_CLASSES))\n",
    "TRAIN_DIR = '../darknet/seals/JPEGImagesBlk'\n",
    "TEST_DIR = '../darknet/seals/JPEGImagesTest'\n",
    "num_class = len(SEAL_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>seal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.894</td>\n",
       "      <td>364.95</td>\n",
       "      <td>295.10</td>\n",
       "      <td>464.95</td>\n",
       "      <td>395.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.893</td>\n",
       "      <td>228.20</td>\n",
       "      <td>376.30</td>\n",
       "      <td>328.20</td>\n",
       "      <td>476.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.720</td>\n",
       "      <td>407.75</td>\n",
       "      <td>409.95</td>\n",
       "      <td>507.75</td>\n",
       "      <td>509.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img  proba      x0      y0      x1      y1  seal\n",
       "0  228_54  0.894  364.95  295.10  464.95  395.10     0\n",
       "1  228_54  0.893  228.20  376.30  328.20  476.30     0\n",
       "2  228_54  0.720  407.75  409.95  507.75  509.95     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "# Fine-tune Example\n",
    "rfcnCVtmp = pd.read_pickle('../coords/rfcnmultiCV.pkl')\n",
    "rfcnCVtmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the previous preds \n",
    "dftmp = pd.concat([pd.read_csv('../coords/vggCVPreds2604_fold2.csv'),\n",
    "                pd.read_csv('../coords/vggCVPreds2604_fold1.csv')])\n",
    "dftmp.columns = ['img1', 'predSeal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6512,\n",
       "         1: 12900,\n",
       "         2: 10070,\n",
       "         3: 6830,\n",
       "         4: 4906,\n",
       "         5: 3199,\n",
       "         6: 2106,\n",
       "         7: 1364,\n",
       "         8: 937,\n",
       "         9: 628,\n",
       "         10: 417,\n",
       "         11: 260,\n",
       "         12: 179,\n",
       "         13: 148,\n",
       "         14: 94,\n",
       "         15: 54,\n",
       "         16: 40,\n",
       "         17: 31,\n",
       "         18: 22,\n",
       "         19: 14,\n",
       "         20: 15,\n",
       "         21: 6,\n",
       "         22: 2,\n",
       "         23: 2,\n",
       "         24: 1,\n",
       "         25: 3})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rfcnCV = pd.concat([rfcnCVtmp.reset_index(drop=True), dftmp.reset_index(drop=True)], axis=1)\n",
    "rfcnCV = rfcnCV[rfcnCV['predSeal']>0.2]\n",
    "Counter(rfcnCV.seal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfcnCV['seal_cut'] = pd.cut(rfcnCV['seal'], bins = [-1,0,1,2,4,10,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>seal</th>\n",
       "      <th>img1</th>\n",
       "      <th>predSeal</th>\n",
       "      <th>seal_cut</th>\n",
       "      <th>seals_0</th>\n",
       "      <th>seals_1</th>\n",
       "      <th>seals_2</th>\n",
       "      <th>seals_3_4</th>\n",
       "      <th>seals_5_10</th>\n",
       "      <th>seals_11+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>332_22</td>\n",
       "      <td>0.998</td>\n",
       "      <td>444.00</td>\n",
       "      <td>9.25</td>\n",
       "      <td>544.00</td>\n",
       "      <td>109.25</td>\n",
       "      <td>1</td>\n",
       "      <td>332_22</td>\n",
       "      <td>0.987439</td>\n",
       "      <td>(0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>332_22</td>\n",
       "      <td>0.925</td>\n",
       "      <td>261.45</td>\n",
       "      <td>195.15</td>\n",
       "      <td>361.45</td>\n",
       "      <td>295.15</td>\n",
       "      <td>1</td>\n",
       "      <td>332_22</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>(0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>448_21</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.00</td>\n",
       "      <td>422.25</td>\n",
       "      <td>100.00</td>\n",
       "      <td>522.25</td>\n",
       "      <td>0</td>\n",
       "      <td>448_21</td>\n",
       "      <td>0.942756</td>\n",
       "      <td>(-1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>338_32</td>\n",
       "      <td>0.958</td>\n",
       "      <td>444.00</td>\n",
       "      <td>444.00</td>\n",
       "      <td>544.00</td>\n",
       "      <td>544.00</td>\n",
       "      <td>2</td>\n",
       "      <td>338_32</td>\n",
       "      <td>0.944517</td>\n",
       "      <td>(1, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>338_32</td>\n",
       "      <td>0.917</td>\n",
       "      <td>444.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>544.00</td>\n",
       "      <td>104.40</td>\n",
       "      <td>2</td>\n",
       "      <td>338_32</td>\n",
       "      <td>0.994015</td>\n",
       "      <td>(1, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       img  proba      x0      y0      x1      y1  seal    img1  predSeal  \\\n",
       "12  332_22  0.998  444.00    9.25  544.00  109.25     1  332_22  0.987439   \n",
       "13  332_22  0.925  261.45  195.15  361.45  295.15     1  332_22  0.999877   \n",
       "18  448_21  0.989    0.00  422.25  100.00  522.25     0  448_21  0.942756   \n",
       "23  338_32  0.958  444.00  444.00  544.00  544.00     2  338_32  0.944517   \n",
       "24  338_32  0.917  444.00    4.40  544.00  104.40     2  338_32  0.994015   \n",
       "\n",
       "   seal_cut  seals_0  seals_1  seals_2  seals_3_4  seals_5_10  seals_11+  \n",
       "12   (0, 1]        0        1        0          0           0          0  \n",
       "13   (0, 1]        0        1        0          0           0          0  \n",
       "18  (-1, 0]        1        0        0          0           0          0  \n",
       "23   (1, 2]        0        0        1          0           0          0  \n",
       "24   (1, 2]        0        0        1          0           0          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make classes\n",
    "rfcnCV['seals_0'] = np.where(rfcnCV['seal']==0, 1, 0)\n",
    "rfcnCV['seals_1'] = np.where(rfcnCV['seal'] == 1, 1, 0)\n",
    "rfcnCV['seals_2'] = np.where(rfcnCV['seal'] == 2, 1, 0)\n",
    "rfcnCV['seals_3_4'] = np.where(rfcnCV['seal'].between(3,4), 1, 0)\n",
    "rfcnCV['seals_5_10'] = np.where(rfcnCV['seal'].between(5,10), 1, 0)\n",
    "rfcnCV['seals_11+'] = np.where(rfcnCV['seal']>10, 1, 0)\n",
    "rfcnCV.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50740, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make our validation set\n",
    "folds = [rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 != 0,\n",
    "        rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 == 0]\n",
    "rfcnCV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby(['seal_cut'], as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "            seal = row[6]\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i] = row[10:] # Add in all classes\n",
    "            i += 1\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)\n",
    "        #return (batch_x.transpose(0, 3, 1, 2), batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testcv_generator(df, datagen = None, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TRAIN_DIR, row[0]+'.jpg')\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file,bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            if datagen is not None: x = datagen.random_transform(x)            \n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%50 == 0: print(batch_index)\n",
    "        #return(batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Part ... A\n",
      "72300\n",
      "74400\n",
      "75300\n",
      "Part ... B\n",
      "Part ... C\n",
      "Epoch 1/5\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.9741 - acc: 0.5907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50048/50000 [==============================] - 2988s - loss: 0.9740 - acc: 0.5908 - val_loss: 1.0264 - val_acc: 0.5460\n",
      "Epoch 2/5\n",
      "50048/50000 [==============================] - 2986s - loss: 0.6766 - acc: 0.7171 - val_loss: 1.0033 - val_acc: 0.5673\n",
      "Epoch 3/5\n",
      "50048/50000 [==============================] - 2985s - loss: 0.5685 - acc: 0.7653 - val_loss: 0.9725 - val_acc: 0.6140\n",
      "Epoch 4/5\n",
      "50048/50000 [==============================] - 2985s - loss: 0.4910 - acc: 0.7999 - val_loss: 1.2319 - val_acc: 0.5613\n",
      "Epoch 5/5\n",
      "50048/50000 [==============================] - 2985s - loss: 0.4223 - acc: 0.8291 - val_loss: 1.1233 - val_acc: 0.5967\n",
      "Part ... D\n",
      "Epoch 1/5\n",
      "50048/50000 [==============================] - 2985s - loss: 0.3646 - acc: 0.8551 - val_loss: 1.1721 - val_acc: 0.5933\n",
      "Epoch 2/5\n",
      "50048/50000 [==============================] - 2983s - loss: 0.2981 - acc: 0.8850 - val_loss: 1.2333 - val_acc: 0.6100\n",
      "Epoch 3/5\n",
      "50048/50000 [==============================] - 2983s - loss: 0.2522 - acc: 0.9042 - val_loss: 1.3105 - val_acc: 0.5967\n",
      "Epoch 4/5\n",
      "50048/50000 [==============================] - 2982s - loss: 0.2123 - acc: 0.9191 - val_loss: 1.4709 - val_acc: 0.5960\n",
      "Epoch 5/5\n",
      "50048/50000 [==============================] - 2981s - loss: 0.1786 - acc: 0.9334 - val_loss: 1.6699 - val_acc: 0.5620\n",
      "Part ... E\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "0\n",
      "Fold: 2\n",
      "Part ... A\n",
      "600\n",
      "3000\n",
      "4200\n",
      "Part ... B\n",
      "Part ... C\n",
      "Epoch 1/5\n",
      "50048/50000 [==============================] - 2980s - loss: 1.1241 - acc: 0.5103 - val_loss: 1.0524 - val_acc: 0.5480\n",
      "Epoch 2/5\n",
      "50048/50000 [==============================] - 2982s - loss: 0.8008 - acc: 0.6508 - val_loss: 1.0095 - val_acc: 0.5613\n",
      "Epoch 3/5\n",
      "50048/50000 [==============================] - 2983s - loss: 0.6810 - acc: 0.6990 - val_loss: 0.9709 - val_acc: 0.5927\n",
      "Epoch 4/5\n",
      "50048/50000 [==============================] - 2982s - loss: 0.5998 - acc: 0.7307 - val_loss: 0.9366 - val_acc: 0.6173\n",
      "Epoch 5/5\n",
      "50048/50000 [==============================] - 2981s - loss: 0.5324 - acc: 0.7500 - val_loss: 1.1132 - val_acc: 0.5800\n",
      "Part ... D\n",
      "Epoch 1/5\n",
      "50048/50000 [==============================] - 2981s - loss: 0.4807 - acc: 0.7680 - val_loss: 1.0843 - val_acc: 0.5927\n",
      "Epoch 2/5\n",
      "50048/50000 [==============================] - 2981s - loss: 0.4350 - acc: 0.7908 - val_loss: 1.1064 - val_acc: 0.5947\n",
      "Epoch 3/5\n",
      "50048/50000 [==============================] - 2979s - loss: 0.3847 - acc: 0.8024 - val_loss: 1.2201 - val_acc: 0.5927\n",
      "Epoch 4/5\n",
      "50048/50000 [==============================] - 2977s - loss: 0.3435 - acc: 0.8043 - val_loss: 1.2343 - val_acc: 0.5973\n",
      "Epoch 5/5\n",
      "50048/50000 [==============================] - 2976s - loss: 0.3010 - acc: 0.8284 - val_loss: 1.2823 - val_acc: 0.5940\n",
      "Part ... E\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for fold in range(2):\n",
    "    print \"Fold: \" + str(fold+1)\n",
    "    train_df = rfcnCV[~folds[fold]]\n",
    "    test_df = rfcnCV[folds[fold]]\n",
    "    valid_df = test_df[:1500]\n",
    "    \n",
    "    # validation_data (valid_x,valid_y)\n",
    "    print \"Part ... A\"\n",
    "    df_1 = valid_df\n",
    "    l = valid_df.groupby('seal').size()\n",
    "    nb_NoF_valid = math.ceil(l.sum()/10)\n",
    "    valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "    valid_y = np.zeros((valid_df.shape[0], len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "    i = 0\n",
    "    for index,row in valid_df.iterrows():\n",
    "        if index % 300 == 0 : print index\n",
    "        row = row.tolist()\n",
    "        image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "        seal = row[6]\n",
    "        bbox = row[2:6]\n",
    "        cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "        x = np.asarray(cropped, dtype=K.floatx())\n",
    "        x = preprocess_input(x)\n",
    "        valid_x[i] = x\n",
    "        valid_y[i] = row[10:]\n",
    "        i += 1\n",
    "    valid_x = valid_x.transpose(0, 3, 1, 2)\n",
    "    valid_x.shape\n",
    "\n",
    "    # Load our model\n",
    "    print \"Part ... B\"\n",
    "    nb_epoch = 5\n",
    "    samples_per_epoch = 50000\n",
    "    model = vgg_std16_model(ROWS, COLS, channel, num_class)\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    print \"Part ... C\"\n",
    "    model.fit_generator(train_generator(train_datagen, train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch, #50000,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    for layer in model.layers[10:]:\n",
    "        layer.trainable = True\n",
    "    model.optimizer.lr = 1e-4\n",
    "    nb_epoch = 5\n",
    "    print \"Part ... D\"\n",
    "    model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    # Test preds save\n",
    "    print \"Part ... E\"\n",
    "    test_preds = model.predict_generator(testcv_generator(test_df), val_samples=test_df.shape[0])\n",
    "    df = pd.concat([test_df.reset_index(drop=True), pd.DataFrame(test_preds,  columns=SEAL_CLASSES)], axis=1)\n",
    "    df.to_pickle('../coords/vggCVMultiPreds1805_fold' + str(fold+1) + '.pkl')\n",
    "    df[[0]+range(15, 20)].to_csv('../coords/vggCVMultiPreds1805_fold' + str(fold+1) + '.csv', index=False)\n",
    "    \n",
    "    # Clean up\n",
    "    del model, train_df, test_df, valid_df, valid_x, df_1\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
