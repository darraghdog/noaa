{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model, trainb_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_class = 2\n",
    "ROWS, COLS = 224, 224\n",
    "BATCHSIZE = 32\n",
    "SEAL_CLASSES = ['NoS', 'seal']\n",
    "nb_perClass = int(BATCHSIZE / len(SEAL_CLASSES))\n",
    "TRAIN_DIR = '../darknet/seals/JPEGImagesBlk'\n",
    "TEST_DIR = '../darknet/seals/JPEGImagesTest'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "# Fine-tune Example\n",
    "rfcnCV = pd.read_pickle('../coords/rfcnCVlo06.pkl')\n",
    "rfcnCV.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets make our validation set\n",
    "folds = [rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 != 0,\n",
    "        rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 == 0]\n",
    "rfcnCV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby(['seal'], as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "            seal = row[6]\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,seal] = 1\n",
    "            i += 1\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)\n",
    "\n",
    "def testcv_generator(df, datagen = None, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TRAIN_DIR, row[0]+'.jpg')\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file,bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            if datagen is not None: x = datagen.random_transform(x)            \n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%50 == 0: print(batch_index)\n",
    "        #return(batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fold in range(2):\n",
    "    print \"Fold: \" + str(fold+1)\n",
    "    train_df = rfcnCV[~folds[fold]]\n",
    "    test_df = rfcnCV[folds[fold]]\n",
    "    valid_df = test_df[:1500]\n",
    "    \n",
    "    # validation_data (valid_x,valid_y)\n",
    "    print \"Part ... A\"\n",
    "    df_1 = valid_df\n",
    "    l = valid_df.groupby('seal').size()\n",
    "    nb_NoF_valid = math.ceil(l.sum()/10)\n",
    "    valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "    valid_y = np.zeros((valid_df.shape[0], len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "    i = 0\n",
    "    for index,row in valid_df.iterrows():\n",
    "        if index % 300 == 0 : print index\n",
    "        row = row.tolist()\n",
    "        image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "        seal = row[6]\n",
    "        bbox = row[2:6]\n",
    "        cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "        x = np.asarray(cropped, dtype=K.floatx())\n",
    "        x = preprocess_input(x)\n",
    "        valid_x[i] = x\n",
    "        valid_y[i,seal] = 1\n",
    "        i += 1\n",
    "    valid_x = valid_x.transpose(0, 3, 1, 2)\n",
    "    valid_x.shape\n",
    "\n",
    "    # Load our model\n",
    "    print \"Part ... B\"\n",
    "    nb_epoch = 2\n",
    "    samples_per_epoch = 50000\n",
    "    model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-3:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    print \"Part ... C\"\n",
    "    model.fit_generator(train_generator(train_datagen, train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch, #50000,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    for layer in model.layers[38:]:\n",
    "        layer.trainable = True\n",
    "    model.optimizer.lr = 1e-5\n",
    "    nb_epoch = 6\n",
    "    print \"Part ... D\"\n",
    "    model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    # Test preds save\n",
    "    print \"Part ... E\"\n",
    "    test_preds = model.predict_generator(testcv_generator(test_df), val_samples=test_df.shape[0])\n",
    "    df = pd.concat([test_df.reset_index(drop=True), pd.DataFrame(test_preds,  columns=['predNoSeal', 'predSeal'])], axis=1)\n",
    "    df.to_pickle('../coords/resnet50CVPredslo06_0105_fold' + str(fold+1) + '.pkl')\n",
    "    df[['img', 'predSeal']].to_csv('../coords/resnet50CVPredslo06_0105_fold' + str(fold+1) + '.csv', index=False)\n",
    "    \n",
    "    # Clean up\n",
    "    del model, train_df, test_df, valid_df, valid_x, df_1\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
