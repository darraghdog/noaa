{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "from cnnmodels import vgg_std16_model, preprocess_input, create_rect5, load_img, train_generator, test_generator\n",
    "from cnnmodels import identity_block, testcv_generator, conv_block, resnet50_model, trainb_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_class = 2\n",
    "ROWS, COLS = 224, 224\n",
    "BATCHSIZE = 32\n",
    "SEAL_CLASSES = ['NoS', 'seal']\n",
    "nb_perClass = int(BATCHSIZE / len(SEAL_CLASSES))\n",
    "TRAIN_DIR = '../darknet/seals/JPEGImagesBlk'\n",
    "TEST_DIR = '../darknet/seals/JPEGImagesTest'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>seal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.894</td>\n",
       "      <td>364.95</td>\n",
       "      <td>295.10</td>\n",
       "      <td>464.95</td>\n",
       "      <td>395.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.893</td>\n",
       "      <td>228.20</td>\n",
       "      <td>376.30</td>\n",
       "      <td>328.20</td>\n",
       "      <td>476.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.720</td>\n",
       "      <td>407.75</td>\n",
       "      <td>409.95</td>\n",
       "      <td>507.75</td>\n",
       "      <td>509.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img  proba      x0      y0      x1      y1  seal\n",
       "0  228_54  0.894  364.95  295.10  464.95  395.10     0\n",
       "1  228_54  0.893  228.20  376.30  328.20  476.30     0\n",
       "2  228_54  0.720  407.75  409.95  507.75  509.95     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "# Fine-tune Example\n",
    "rfcnCV = pd.read_pickle('../coords/rfcnCVlo06.pkl')\n",
    "rfcnCV.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264142, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make our validation set\n",
    "folds = [rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 != 0,\n",
    "        rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 2 == 0]\n",
    "rfcnCV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby(['seal'], as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "            seal = row[6]\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,seal] = 1\n",
    "            i += 1\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)\n",
    "\n",
    "def testcv_generator(df, datagen = None, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TRAIN_DIR, row[0]+'.jpg')\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file,bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            if datagen is not None: x = datagen.random_transform(x)            \n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%50 == 0: print(batch_index)\n",
    "        #return(batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Part ... A\n",
      "103200\n",
      "103500\n",
      "103800\n",
      "104100\n",
      "104400\n",
      "Part ... B\n",
      "Part ... C\n",
      "Epoch 1/2\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50016/50000 [==============================] - 2628s - loss: 0.1222 - acc: 0.9540 - val_loss: 0.0751 - val_acc: 0.9793\n",
      "Epoch 2/2\n",
      "50016/50000 [==============================] - 2616s - loss: 0.0796 - acc: 0.9720 - val_loss: 0.0677 - val_acc: 0.9813\n",
      "Part ... D\n",
      "Epoch 1/6\n",
      "50016/50000 [==============================] - 2640s - loss: 0.0605 - acc: 0.9787 - val_loss: 0.0469 - val_acc: 0.9860\n",
      "Epoch 2/6\n",
      "50016/50000 [==============================] - 2688s - loss: 0.0511 - acc: 0.9825 - val_loss: 0.0426 - val_acc: 0.9867\n",
      "Epoch 3/6\n",
      "50016/50000 [==============================] - 2626s - loss: 0.0418 - acc: 0.9857 - val_loss: 0.0478 - val_acc: 0.9860\n",
      "Epoch 4/6\n",
      "50016/50000 [==============================] - 2629s - loss: 0.0342 - acc: 0.9888 - val_loss: 0.0513 - val_acc: 0.9840\n",
      "Epoch 5/6\n",
      "50016/50000 [==============================] - 2629s - loss: 0.0338 - acc: 0.9885 - val_loss: 0.0439 - val_acc: 0.9873\n",
      "Epoch 6/6\n",
      "50016/50000 [==============================] - 2631s - loss: 0.0277 - acc: 0.9907 - val_loss: 0.0522 - val_acc: 0.9873\n",
      "Part ... E\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n",
      "3850\n",
      "3900\n",
      "3950\n",
      "4000\n",
      "4050\n",
      "4100\n",
      "4150\n",
      "4200\n",
      "4250\n",
      "4300\n",
      "4350\n",
      "4400\n",
      "4450\n",
      "4500\n",
      "4550\n",
      "4600\n",
      "4650\n",
      "4700\n",
      "4750\n",
      "4800\n",
      "4850\n",
      "4900\n",
      "4950\n",
      "5000\n",
      "0\n",
      "Fold: 2\n",
      "Part ... A\n",
      "0\n",
      "300\n",
      "600\n",
      "900\n",
      "1200\n",
      "Part ... B\n",
      "Part ... C\n",
      "Epoch 1/2\n",
      "50016/50000 [==============================] - 2631s - loss: 0.0963 - acc: 0.9661 - val_loss: 0.1215 - val_acc: 0.9673\n",
      "Epoch 2/2\n",
      "50016/50000 [==============================] - 2631s - loss: 0.0564 - acc: 0.9807 - val_loss: 0.1253 - val_acc: 0.9607\n",
      "Part ... D\n",
      "Epoch 1/6\n",
      "50016/50000 [==============================] - 2632s - loss: 0.0467 - acc: 0.9837 - val_loss: 0.1310 - val_acc: 0.9553\n",
      "Epoch 2/6\n",
      "50016/50000 [==============================] - 2633s - loss: 0.0410 - acc: 0.9869 - val_loss: 0.1164 - val_acc: 0.9620\n",
      "Epoch 3/6\n",
      "50016/50000 [==============================] - 2634s - loss: 0.0349 - acc: 0.9880 - val_loss: 0.0795 - val_acc: 0.9787\n",
      "Epoch 4/6\n",
      "50016/50000 [==============================] - 2634s - loss: 0.0288 - acc: 0.9901 - val_loss: 0.0762 - val_acc: 0.9747\n",
      "Epoch 5/6\n",
      "50016/50000 [==============================] - 2633s - loss: 0.0284 - acc: 0.9907 - val_loss: 0.1049 - val_acc: 0.9733\n",
      "Epoch 6/6\n",
      "50016/50000 [==============================] - 2632s - loss: 0.0232 - acc: 0.9930 - val_loss: 0.0728 - val_acc: 0.9780\n",
      "Part ... E\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for fold in range(2):\n",
    "    print \"Fold: \" + str(fold+1)\n",
    "    train_df = rfcnCV[~folds[fold]]\n",
    "    test_df = rfcnCV[folds[fold]]\n",
    "    valid_df = test_df[:1500]\n",
    "    \n",
    "    # validation_data (valid_x,valid_y)\n",
    "    print \"Part ... A\"\n",
    "    df_1 = valid_df\n",
    "    l = valid_df.groupby('seal').size()\n",
    "    nb_NoF_valid = math.ceil(l.sum()/10)\n",
    "    valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "    valid_y = np.zeros((valid_df.shape[0], len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "    i = 0\n",
    "    for index,row in valid_df.iterrows():\n",
    "        if index % 300 == 0 : print index\n",
    "        row = row.tolist()\n",
    "        image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "        seal = row[6]\n",
    "        bbox = row[2:6]\n",
    "        cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "        x = np.asarray(cropped, dtype=K.floatx())\n",
    "        x = preprocess_input(x)\n",
    "        valid_x[i] = x\n",
    "        valid_y[i,seal] = 1\n",
    "        i += 1\n",
    "    valid_x = valid_x.transpose(0, 3, 1, 2)\n",
    "    valid_x.shape\n",
    "\n",
    "    # Load our model\n",
    "    print \"Part ... B\"\n",
    "    nb_epoch = 2\n",
    "    samples_per_epoch = 50000\n",
    "    model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-3:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    print \"Part ... C\"\n",
    "    model.fit_generator(train_generator(train_datagen, train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch, #50000,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    for layer in model.layers[38:]:\n",
    "        layer.trainable = True\n",
    "    model.optimizer.lr = 1e-5\n",
    "    nb_epoch = 6\n",
    "    print \"Part ... D\"\n",
    "    model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "              nb_epoch=nb_epoch,\n",
    "              samples_per_epoch=samples_per_epoch,\n",
    "              verbose=1,\n",
    "              validation_data=(valid_x, valid_y),\n",
    "              )\n",
    "\n",
    "    # Test preds save\n",
    "    print \"Part ... E\"\n",
    "    test_preds = model.predict_generator(testcv_generator(test_df), val_samples=test_df.shape[0])\n",
    "    df = pd.concat([test_df.reset_index(drop=True), pd.DataFrame(test_preds,  columns=['predNoSeal', 'predSeal'])], axis=1)\n",
    "    df.to_pickle('../coords/resnet50CVPredslo06_0105_fold' + str(fold+1) + '.pkl')\n",
    "    df[['img', 'predSeal']].to_csv('../coords/resnet50CVPredslo06_0105_fold' + str(fold+1) + '.csv', index=False)\n",
    "    \n",
    "    # Clean up\n",
    "    del model, train_df, test_df, valid_df, valid_x, df_1\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
