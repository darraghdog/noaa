{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc, math\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline  \n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"\n",
    "    The identity_block is the block that has no conv layer at shortcut\n",
    "    Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    \"\"\"\n",
    "\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      border_mode='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='sum')\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"\n",
    "    conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    \"\"\"\n",
    "\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n",
    "                             name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = merge([x, shortcut], mode='sum')\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet50_model(img_rows, img_cols, color_type=1, num_class=None):\n",
    "    \"\"\"\n",
    "    Resnet 50 Model for Keras\n",
    "    Model Schema is based on \n",
    "    https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n",
    "    ImageNet Pretrained Weights \n",
    "    https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels.h5\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_class - number of class labels for our classification task\n",
    "    \"\"\"\n",
    "\n",
    "    bn_axis = 1\n",
    "    img_input = Input(shape=(color_type, img_rows, img_cols))\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = Convolution2D(64, 7, 7, subsample=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # Fully Connected Softmax Layer\n",
    "    x_fc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x_fc = Flatten()(x_fc)\n",
    "    x_fc = Dense(1000, activation='softmax', name='fc1000')(x_fc)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x_fc)\n",
    "\n",
    "    # Load ImageNet pre-trained data \n",
    "    model.load_weights('../cache/resnet50_weights_th_dim_ordering_th_kernels.h5')\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    # Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "    # The method below works since pre-trained weights are stored in layers but not in the model\n",
    "    x_newfc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x_newfc = Flatten()(x_newfc)\n",
    "    x_newfc = Dense(num_class, activation='softmax', name='fc10')(x_newfc)\n",
    "\n",
    "    # Create another model with our customized softmax\n",
    "    model = Model(img_input, x_newfc)\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def preprocess_input(x):\n",
    "    #resnet50 image preprocessing\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    x[:, :, 0] -= 100\n",
    "    x[:, :, 1] -= 115\n",
    "    x[:, :, 2] -= 124\n",
    "    return x\n",
    "\n",
    "def create_rect5(row):\n",
    "    if is_seal:\n",
    "        return plt.Rectangle((row['x0'], row['y0']), row['w'], row['h'], color='red', fill=False, lw=2)\n",
    "    else:\n",
    "        return plt.Rectangle((row['x0'], row['y0']), row['w'], row['h'], color='red', fill=False, lw=4)\n",
    "\n",
    "def load_img(path, bbox, target_size=None):\n",
    "    img = Image.open(path)\n",
    "    img = img.convert('RGB')\n",
    "    cropped = img.crop((bbox[0],bbox[1],bbox[2],bbox[3]))\n",
    "    if target_size:\n",
    "        cropped = cropped.resize((target_size[1], target_size[0]))\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_class = 2\n",
    "ROWS, COLS = 224, 224\n",
    "BATCHSIZE = 32\n",
    "SEAL_CLASSES = ['NoS', 'seal']\n",
    "nb_perClass = int(BATCHSIZE / len(SEAL_CLASSES))\n",
    "TRAIN_DIR = '../darknet/seals/JPEGImagesBlk'\n",
    "TEST_DIR = '../darknet/seals/JPEGImagesTest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>seal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.894</td>\n",
       "      <td>364.95</td>\n",
       "      <td>295.10</td>\n",
       "      <td>464.95</td>\n",
       "      <td>395.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.893</td>\n",
       "      <td>228.20</td>\n",
       "      <td>376.30</td>\n",
       "      <td>328.20</td>\n",
       "      <td>476.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228_54</td>\n",
       "      <td>0.720</td>\n",
       "      <td>407.75</td>\n",
       "      <td>409.95</td>\n",
       "      <td>507.75</td>\n",
       "      <td>509.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img  proba      x0      y0      x1      y1  seal\n",
       "0  228_54  0.894  364.95  295.10  464.95  395.10     0\n",
       "1  228_54  0.893  228.20  376.30  328.20  476.30     0\n",
       "2  228_54  0.720  407.75  409.95  507.75  509.95     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune Example\n",
    "rfcnCV = pd.read_pickle('../coords/rfcnCVlo06.pkl')\n",
    "rfcnCV.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264142, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcnCV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3ce5d70510>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAFkCAYAAAAOihAyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+FoIuAE+pdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d0af03290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfcnCV.seal.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>proba</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13835_33</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13835_33</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13835_33</td>\n",
       "      <td>0.635</td>\n",
       "      <td>444.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        img  proba     x0     y0     x1     y1\n",
       "0  13835_33  0.967    0.0  444.0  100.0  544.0\n",
       "1  13835_33  0.638    0.0    0.0  100.0  100.0\n",
       "2  13835_33  0.635  444.0    0.0  544.0  100.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune Example\n",
    "test_df = pd.read_pickle('../coords/rfcnTstlo06.pkl')\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4776936, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_generator(datagen, df):\n",
    "    while 1:\n",
    "        batch_x = np.zeros((BATCHSIZE, ROWS, COLS, 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((BATCHSIZE, len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "        fn = lambda obj: obj.loc[np.random.choice(obj.index, size=nb_perClass, replace=False),:]\n",
    "        batch_df = df.groupby(['seal'], as_index=True).apply(fn)\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "            seal = row[6]\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            x = datagen.random_transform(x)\n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i,seal] = 1\n",
    "            i += 1\n",
    "        yield (batch_x.transpose(0, 3, 1, 2), batch_y)\n",
    "\n",
    "def test_generator(df, datagen = None, batch_size = BATCHSIZE):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            row = row.tolist()\n",
    "            image_file = os.path.join(TEST_DIR, row[0]+'.jpg')\n",
    "            bbox = row[2:6]\n",
    "            cropped = load_img(image_file,bbox,target_size=(ROWS,COLS))\n",
    "            x = np.asarray(cropped, dtype=K.floatx())\n",
    "            if datagen is not None: x = datagen.random_transform(x)            \n",
    "            x = preprocess_input(x)\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%50 == 0: print(batch_index)\n",
    "        #return(batch_x.transpose(0, 3, 1, 2))\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))\n",
    "        \n",
    "# Data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5898, 3, 224, 224)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make our validation set\n",
    "CVsplit = rfcnCV.img.str.split('_').apply(lambda x: x[0]).astype(int) % 40 == 0\n",
    "train_df = rfcnCV[~CVsplit]\n",
    "valid_df = rfcnCV[CVsplit]\n",
    "\n",
    "# validation_data (valid_x,valid_y)\n",
    "df_1 = valid_df\n",
    "l = valid_df.groupby('seal').size()\n",
    "nb_NoF_valid = math.ceil(l.sum()/10)\n",
    "valid_x = np.zeros((valid_df.shape[0], ROWS, COLS, 3), dtype=K.floatx())\n",
    "valid_y = np.zeros((valid_df.shape[0], len(SEAL_CLASSES)), dtype=K.floatx())\n",
    "i = 0\n",
    "for index,row in valid_df.iterrows():\n",
    "    row = row.tolist()\n",
    "    image_file = os.path.join(TRAIN_DIR, row[0])\n",
    "    seal = row[6]\n",
    "    bbox = row[2:6]\n",
    "    cropped = load_img(image_file+'.jpg',bbox,target_size=(ROWS,COLS))\n",
    "    x = np.asarray(cropped, dtype=K.floatx())\n",
    "    x = preprocess_input(x)\n",
    "    valid_x[i] = x\n",
    "    valid_y[i,seal] = 1\n",
    "    i += 1\n",
    "valid_x = valid_x.transpose(0, 3, 1, 2)\n",
    "valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140000/140000 [==============================] - 7432s - loss: 0.0821 - acc: 0.9710 - val_loss: 0.0993 - val_acc: 0.9674\n",
      "Epoch 2/2\n",
      "140000/140000 [==============================] - 7405s - loss: 0.0506 - acc: 0.9830 - val_loss: 0.0615 - val_acc: 0.9798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bbdbeef10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our model\n",
    "nb_epoch = 2\n",
    "samples_per_epoch = 140000\n",
    "model = resnet50_model(ROWS, COLS, channel, num_class)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Start Fine-tuning\n",
    "model.fit_generator(train_generator(train_datagen, train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch, #50000,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "   448/140000 [..............................] - ETA: 7670s - loss: 0.0465 - acc: 0.9844"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[38:]:\n",
    "    layer.trainable = True\n",
    "model.optimizer.lr = 1e-5\n",
    "nb_epoch = 6\n",
    "model.fit_generator(train_generator(train_datagen, df=train_df),\n",
    "          nb_epoch=nb_epoch,\n",
    "          samples_per_epoch=samples_per_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(valid_x, valid_y),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_preds = test_model.predict_generator(test_generator(test_df), val_samples=test_df.shape[0]))\n",
    "test_preds = model.predict_generator(test_generator(test_df), val_samples=test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([test_df, pd.DataFrame(test_preds,  columns=['predNoSeal', 'predSeal'])], axis=1)\n",
    "df.to_pickle('../coords/resnet50TestPredslo06_0105.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['img', 'predSeal']].to_csv('../coords/resnet50TestPredslo06_0105.csv', index=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('checkpoints/model_resnet50TestPreds_lo06_0105.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
