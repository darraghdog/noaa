{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, MaxPooling2D, UpSampling2D, Conv2D\n",
    "#from keras.layers import concatenate\n",
    "#from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave, imread\n",
    "from segmodels import dice_coef, dice_coef_loss, double_conv_layer\n",
    "from segmodels import create_model, preprocess_img, preprocess, test_generator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'th'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows = 512\n",
    "img_cols = 512\n",
    "batch_size = 4\n",
    "nb_epoch = 10\n",
    "print(img_rows, img_cols)\n",
    "data_path = '/home/ubuntu/noaa/darknet/seals/'\n",
    "train_path = 'JPEGImagesBlk'\n",
    "test_path  = 'JPEGImagesTest'\n",
    "train_mask_path = '../data/mask/all/'\n",
    "pred_dir = '../data/mask/all_pred/'\n",
    "smooth = 1.\n",
    "K.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_data(path, exclude = []):\n",
    "    images = os.listdir(train_mask_path)\n",
    "    images = [i for i in images if i not in exclude]\n",
    "    total = len(images)\n",
    "    imgs = np.ndarray((total, img_rows, img_cols, 3), dtype=np.float32)\n",
    "    imgs_mask = np.ndarray((total, img_rows, img_cols), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    for image_mask_name in images:\n",
    "        image_name = image_mask_name.split('.')[0] + '.jpg'\n",
    "        #image_mask_name = image_name.split('.')[0] + '_mask.tif'\n",
    "        img = imread(os.path.join(data_path, train_path, image_name), as_grey=False)\n",
    "        img_mask = imread(os.path.join(train_mask_path, image_mask_name), as_grey=True)\n",
    "        img = resize(img, (img_rows, img_cols), mode='reflect')\n",
    "        img_mask = resize(img_mask, (img_rows, img_cols), mode='reflect')\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "        if i % 500 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "    return imgs, imgs_mask\n",
    "\n",
    "def test_generator(df, batch_size = 4):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], img_rows, img_cols, 3)).astype('float32')\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            img = imread(os.path.join(data_path, test_path, row[0]), as_grey=False)\n",
    "            img = resize(img, (img_rows, img_cols), mode='reflect')\n",
    "            x = np.array([img])\n",
    "            x -= mean\n",
    "            x /= std\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%300 == 0: print(batch_index)\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Directory structure...\n",
      "------------------------------\n",
      "('JPEGImagesBlk', 'JPEGImagesTest', '../data/mask/all_pred/')\n",
      "------------------------------\n",
      "Creating training images...\n",
      "------------------------------\n",
      "Done: 0/3755 images\n",
      "Done: 500/3755 images\n",
      "Done: 1000/3755 images\n"
     ]
    }
   ],
   "source": [
    "for fold in range(1,2):\n",
    "    print('-'*30)\n",
    "    print('Directory structure...')\n",
    "    print('-'*30)\n",
    "    print(train_path , test_path , pred_dir )\n",
    "    \n",
    "    # exclude any not in that fold\n",
    "    images = os.listdir(train_mask_path)\n",
    "    images = [i for i in images if '.tif' in i]\n",
    "    exclude = [i for i in images if int(i.split('_')[0])%2==fold]\n",
    "    \n",
    "    imgs_train, imgs_mask_train = train_data(train_path, exclude)\n",
    "    imgs_train = preprocess_img(imgs_train, img_rows, img_cols, 3)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train, img_rows, img_cols, 1)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "\n",
    "    imgs_train = imgs_train[:,:,:,:,0]\n",
    "    imgs_mask_train = imgs_mask_train[:,:,:,:,0]\n",
    "\n",
    "    #del model\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = create_model(img_rows, img_cols, 3)\n",
    "    model_checkpoint = ModelCheckpoint('weights_seg.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    optim = Adam(lr=.001)\n",
    "    model.compile(optimizer=optim, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    model.fit(imgs_train.transpose(0, 3, 1, 2), imgs_mask_train.transpose(0, 3, 1, 2), batch_size=batch_size, \n",
    "              verbose=1, shuffle=True, nb_epoch=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting test...')\n",
    "    print('-'*30)\n",
    "    test_df = [f.split('.')[0]+'.jpg' for f in exclude]\n",
    "    test_df = pd.DataFrame(test_df)\n",
    "    imgs_mask_test = model.predict_generator(test_generator(test_df),  \n",
    "                                             val_samples = test_df.shape[0])\n",
    "    imgs_mask_test = imgs_mask_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for i in range(len(imgs_mask_test)):\n",
    "        fname = test_df[0][i].split('.')[0]\n",
    "        imsave(os.path.join(pred_dir, str(fname) + '_pred.png'), imgs_mask_test[i][:,:,0])\n",
    "        \n",
    "    del imgs_train, imgs_mask_train, imgs_mask_test\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
