{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1169"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, gc, gzip\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, MaxPooling2D, UpSampling2D, Conv2D\n",
    "#from keras.layers import concatenate\n",
    "#from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave, imread\n",
    "from skimage.transform import resize \n",
    "from skimage import draw\n",
    "#from seg_noaa import load_train_data, load_test_data\n",
    "from segmodels import dice_coef, dice_coef_loss, double_conv_layer\n",
    "from segmodels import create_model, preprocess_img, preprocess, test_generator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(544, 544)\n"
     ]
    }
   ],
   "source": [
    "img_rows = 544\n",
    "img_cols = 544\n",
    "batch_size = 4\n",
    "nb_epoch = 25\n",
    "print(img_rows, img_cols)\n",
    "data_path = '/home/ubuntu/noaa/darknet/seals/'\n",
    "train_data_path = os.path.join(data_path, 'JPEGImagesBlk')\n",
    "mask_data_path = '/home/ubuntu/noaa/data/mask/classesShallow'\n",
    "MASK_FOLDER = os.path.join(mask_data_path, 'train')\n",
    "smooth = 1.\n",
    "K.image_dim_ordering()\n",
    "classes = 5\n",
    "OUTPUT_MASK_CHANNELS = 5\n",
    "MAKE_TRAIN_MASKS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeDir(name):\n",
    "    if not os.path.exists(name):\n",
    "        os.mkdir(name)\n",
    "\n",
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in xrange(0, len(l), n))\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def double_conv_layer(x, size, dropout, batch_norm):\n",
    "    conv = Convolution2D(size, 3, 3, border_mode='same')(x)\n",
    "    if batch_norm == True:\n",
    "        conv = BatchNormalization(mode=0, axis=1)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Convolution2D(size, 3, 3, border_mode='same')(conv)\n",
    "    if batch_norm == True:\n",
    "        conv = BatchNormalization(mode=0, axis=1)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = Dropout(dropout)(conv)\n",
    "    return conv\n",
    "\n",
    "def create_model(dropout_val=0.05, batch_norm=True):\n",
    "    inputs = Input((3, img_rows, img_cols))\n",
    "    conv1 = double_conv_layer(inputs, 32, dropout_val, batch_norm)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = double_conv_layer(pool1, 64, dropout_val, batch_norm)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = double_conv_layer(pool2, 128, dropout_val, batch_norm)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = double_conv_layer(pool3, 256, dropout_val, batch_norm)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = double_conv_layer(pool4, 512, dropout_val, batch_norm)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "\n",
    "    conv6 = double_conv_layer(pool5, 1024, dropout_val, batch_norm)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv6), conv5], mode='concat', concat_axis=1)\n",
    "    conv7 = double_conv_layer(up6, 512, dropout_val, batch_norm)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv7), conv4], mode='concat', concat_axis=1)\n",
    "    conv8 = double_conv_layer(up7, 256, dropout_val, batch_norm)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv8), conv3], mode='concat', concat_axis=1)\n",
    "    conv9 = double_conv_layer(up8, 128, dropout_val, batch_norm)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv9), conv2], mode='concat', concat_axis=1)\n",
    "    conv10 = double_conv_layer(up9, 64, dropout_val, batch_norm)\n",
    "\n",
    "    up10 = merge([UpSampling2D(size=(2, 2))(conv10), conv1], mode='concat', concat_axis=1)\n",
    "    conv11 = double_conv_layer(up10, 32, 0, batch_norm)\n",
    "\n",
    "    conv12 = Convolution2D(OUTPUT_MASK_CHANNELS, 1, 1)(conv11)\n",
    "    conv12 = BatchNormalization(mode=0, axis=1)(conv12)\n",
    "    conv12 = Activation('sigmoid')(conv12)\n",
    "\n",
    "    model = Model(input=inputs, output=conv12)\n",
    "    return model\n",
    "\n",
    "def create_shallow_model(dropout_val=0.05, batch_norm=True):\n",
    "    inputs = Input((3, img_rows, img_cols))\n",
    "    conv1 = double_conv_layer(inputs, 32, dropout_val, batch_norm) # 544\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = double_conv_layer(pool1, 64, dropout_val, batch_norm) # 272\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = double_conv_layer(pool2, 128, dropout_val, batch_norm) # 136\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    #conv4 = double_conv_layer(pool3, 256, dropout_val, batch_norm) \n",
    "    #pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    #conv5 = double_conv_layer(pool4, 512, dropout_val, batch_norm)\n",
    "    #pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "\n",
    "    #conv6 = double_conv_layer(pool5, 1024, dropout_val, batch_norm) \n",
    "    conv6 = double_conv_layer(pool3, 256, dropout_val, batch_norm) # 68\n",
    "\n",
    "    #up6 = merge([UpSampling2D(size=(2, 2))(conv6), conv5], mode='concat', concat_axis=1)\n",
    "    #conv7 = double_conv_layer(up6, 512, dropout_val, batch_norm)\n",
    "\n",
    "    #up7 = merge([UpSampling2D(size=(2, 2))(conv7), conv4], mode='concat', concat_axis=1)\n",
    "    #conv8 = double_conv_layer(up7, 256, dropout_val, batch_norm)\n",
    "\n",
    "    #up8 = merge([UpSampling2D(size=(2, 2))(conv8), conv3], mode='concat', concat_axis=1)\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1) # 136\n",
    "    conv9 = double_conv_layer(up8, 128, dropout_val, batch_norm)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv9), conv2], mode='concat', concat_axis=1) # 272\n",
    "    conv10 = double_conv_layer(up9, 64, dropout_val, batch_norm)\n",
    "\n",
    "    up10 = merge([UpSampling2D(size=(2, 2))(conv10), conv1], mode='concat', concat_axis=1) # 544\n",
    "    conv11 = double_conv_layer(up10, 32, 0, batch_norm)\n",
    "\n",
    "    conv12 = Convolution2D(OUTPUT_MASK_CHANNELS, 1, 1)(conv11)\n",
    "    conv12 = BatchNormalization(mode=0, axis=1)(conv12)\n",
    "    conv12 = Activation('sigmoid')(conv12)\n",
    "\n",
    "    model = Model(input=inputs, output=conv12)\n",
    "    return model\n",
    "\n",
    "def preprocess_img(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols, 3), dtype=np.float32)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows, 3), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    "\n",
    "def preprocess_mask(imgs, channels=5):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols, channels), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = multi_resize(imgs[i])\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    "\n",
    "def show_mask(img):\n",
    "    imout = np.zeros((img.shape[0]*2, img.shape[1]*3), dtype=np.uint8)\n",
    "    for i in range(5):\n",
    "        y_pos, x_pos = math.floor(i/3)*img.shape[0], i%3*img.shape[0]\n",
    "        imout[int(y_pos):int((y_pos+img.shape[0])), int(x_pos):int((x_pos+img.shape[0]))] = img[:,:,i]\n",
    "        imout[int(y_pos):int(y_pos)+2,:] = 1\n",
    "        imout[:,int(x_pos):int(x_pos)+2] = 1\n",
    "    plt.imshow(imout)\n",
    "    plt.show()\n",
    "    \n",
    "def multi_resize(img_mask, image_rows=img_rows, image_cols=img_cols, classes=classes):\n",
    "    imout = np.ndarray((image_rows, image_cols, classes), dtype=np.uint8)\n",
    "    for i in range(classes):\n",
    "        imout[:,:,i] = resize(img_mask[:,:,i].astype(np.float32), (img_rows, img_cols), mode='reflect')\n",
    "    return imout\n",
    "\n",
    "def create_train_data(images, classes=5):\n",
    "    total = len(images) \n",
    "    imgs = np.ndarray((total, img_rows, img_cols, 3), dtype=np.float32)\n",
    "    imgs_mask = np.ndarray((total, img_rows, img_cols, classes), dtype=np.uint8)\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    for image_mask_name in images:\n",
    "        image_name = image_mask_name.split('.')[0] + '.jpg'\n",
    "        \n",
    "        #img_mask = np.load(os.path.join(mask_data_path,'train', image_mask_name))\n",
    "        f = gzip.GzipFile(os.path.join(mask_data_path, 'train', image_mask_name), \"r\")\n",
    "        try:\n",
    "            img_mask = np.load(f)\n",
    "        except:\n",
    "            print ('failed to load ..' , image_name)\n",
    "            continue\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=False)\n",
    "        \n",
    "        img = resize(img, (img_rows, img_cols), mode='reflect')\n",
    "        img_mask = multi_resize(img_mask)\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "    return imgs, imgs_mask\n",
    "\n",
    "def test_generator(df, input_folder, batch_size = 16):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], img_rows, img_cols, 3)).astype('float32')\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            img = imread(os.path.join(data_path, input_folder, row[0]+'.jpg'), as_grey=False)\n",
    "            img = resize(img, (img_rows, img_cols), mode='reflect')\n",
    "            x = np.array([img])\n",
    "            x -= mean\n",
    "            x /= std\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        if batch_index%300 == 0: print(batch_index)\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if MAKE_TRAIN_MASKS:\n",
    "    # Load up the coordinates\n",
    "    coords = pd.read_csv(\"../coords/block_coords.csv\")\n",
    "    coords = coords[['id', 'block', 'class', 'block_width', 'block_height']]\n",
    "    img_files = coords[['id', 'block']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Process training images\n",
    "    vggCVpred = pd.concat([pd.read_csv('../coords/vggCVPreds2604_fold1.csv'),\n",
    "               pd.read_csv('../coords/vggCVPreds2604_fold2.csv')], axis = 0)\n",
    "    idx = vggCVpred.groupby(['img'])['predSeal'].transform(max) == vggCVpred['predSeal']\n",
    "    vggCVpred = vggCVpred[idx]\n",
    "    vggCVpred = vggCVpred[vggCVpred['predSeal']>0.7].reset_index(drop=True)\n",
    "    vggCVpred['id'] = vggCVpred['img'].map(lambda x: int(x.split('_')[0]))\n",
    "    vggCVpred['block'] = vggCVpred['img'].map(lambda x: x.split('_')[1])\n",
    "\n",
    "    img_all = os.listdir('../darknet/seals/JPEGImagesBlk')\n",
    "    for c, row in vggCVpred.reset_index(drop=True).iterrows():\n",
    "        if c % 1000== 0 : \n",
    "            print \"Row: \" + str(c)\n",
    "        tif = np.zeros((544,544, classes), dtype=np.uint8)\n",
    "        if row['id'] in coords.id:\n",
    "            dftmp = coords[(coords['id']==row['id']) & (coords['block']==int(row['block'])) ].reset_index(drop=True)\n",
    "            for c1, row1 in dftmp.iterrows():\n",
    "                radius = 20 #boundaries[row1['class']]/2\n",
    "                rr, cc = draw.circle(row1['block_height'], row1['block_width'], radius=radius, shape=tif.shape)\n",
    "                tif[rr, cc, row1['class']] = 1\n",
    "\n",
    "        #np.save(MASK_FOLDER +'/%s_%s'%(row[2], row[3]), tif)            \n",
    "        f = gzip.GzipFile(MASK_FOLDER +'/%s_%s.npy.gz'%(row[2], row[3]), \"w\")\n",
    "        np.save(file=f, arr=tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7685"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = os.listdir(os.path.join(mask_data_path,'train'))\n",
    "images = [i for i in images if '.npy' in i]\n",
    "img_folds = [[i for i in images if int(i.split('_')[0])%2==0], [i for i in images if int(i.split('_')[0])%2==1]]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['11710_62', '17920_13', '15778_83', '17146_84', '854_02']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggTest = pd.read_csv('../coords/vggTestPreds2604.csv')\n",
    "idx = vggTest.groupby(['img'])['predSeal'].transform(max) == vggTest['predSeal']\n",
    "vggTest = vggTest[idx]\n",
    "vggTest = vggTest[vggTest['predSeal']>0.7].reset_index(drop=True)\n",
    "imagesTst = vggTest.img.unique().tolist()\n",
    "print(len(imagesTst))\n",
    "imagesTst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_generator(df, input_folder, batch_size = 16):\n",
    "    n = df.shape[0]\n",
    "    batch_index = 0\n",
    "    while 1:\n",
    "        current_index = batch_index * batch_size\n",
    "        if n >= current_index + batch_size:\n",
    "            current_batch_size = batch_size\n",
    "            batch_index += 1    \n",
    "        else:\n",
    "            current_batch_size = n - current_index\n",
    "            batch_index = 0        \n",
    "        batch_df = df[current_index:current_index+current_batch_size]\n",
    "        batch_x = np.zeros((batch_df.shape[0], img_rows, img_cols, 3)).astype('float32')\n",
    "        i = 0\n",
    "        for index,row in batch_df.iterrows():\n",
    "            img = imread(os.path.join(data_path, input_folder, row[0]+'.jpg'), as_grey=False)\n",
    "            img = resize(img, (img_rows, img_cols), mode='reflect')\n",
    "            x = np.array([img])\n",
    "            x -= mean\n",
    "            x /= std\n",
    "            batch_x[i] = x\n",
    "            i += 1\n",
    "        yield(batch_x.transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fold in range(2):\n",
    "    print('-'*30)\n",
    "    print('Upload data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train = create_train_data(img_folds[fold], classes=5)\n",
    "    imgs_train = preprocess_img(imgs_train)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Process data...')\n",
    "    print('-'*30)\n",
    "    imgs_mask_train = preprocess_mask(imgs_mask_train)\n",
    "    #imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_train = imgs_train[:,:,:,:,0]\n",
    "    imgs_mask_train = imgs_mask_train[:,:,:,:,0]\n",
    "\n",
    "    #del model\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = create_shallow_model()\n",
    "    model_checkpoint = ModelCheckpoint('weights_classshallow_fold'+str(fold)+'.h5', monitor='val_loss', save_best_only=True)\n",
    "    #model.load_weights('weights_class_fold'+str(fold)+'.h5')\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    optim = Adam(lr=.001)\n",
    "    model.compile(optimizer=optim, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    model.fit(imgs_train.transpose(0, 3, 1, 2), imgs_mask_train.transpose(0, 3, 1, 2), batch_size=batch_size, \n",
    "              verbose=1, shuffle=True, nb_epoch=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks...')\n",
    "    print('-'*30)\n",
    "    imgs_test, tmp  = create_train_data(img_folds[abs(fold-1)], classes=5)\n",
    "    imgs_test = preprocess_img(imgs_test)\n",
    "    del tmp\n",
    "    gc.collect()\n",
    "\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "    imgs_test = imgs_test[:,:,:,:,0]\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    imgs_mask_test = model.predict(imgs_test.transpose(0, 3, 1, 2), batch_size=16, verbose=1)\n",
    "    imgs_mask_test = imgs_mask_test.transpose(0, 2, 3, 1).astype(np.uint8)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = os.path.join(mask_data_path, 'traincv')\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, img_folds[abs(fold-1)]):\n",
    "        f = gzip.GzipFile(os.path.join(pred_dir, image_id.split('.')[0]+\".npy.gz\"), \"w\")\n",
    "        np.save(file=f, arr=image)\n",
    "        # np.save(os.path.join(pred_dir, image_id), image)\n",
    "    c = 0\n",
    "    chunk_list = chunks(imagesTst, 1000)\n",
    "    for img_chunk in chunk_list:\n",
    "        test_df = pd.DataFrame(img_chunk, columns = ['img'])\n",
    "        c += 1\n",
    "        print('-'*30)\n",
    "        print('Predicting masks on test data..., chunk...' + str(c))\n",
    "        print('-'*30)\n",
    "        imgs_mask_test = model.predict_generator(test_generator(test_df, 'JPEGImagesTest'),  \n",
    "                                                 val_samples = test_df.shape[0])\n",
    "        imgs_mask_test = imgs_mask_test.transpose(0, 2, 3, 1).astype(np.uint8)\n",
    "\n",
    "        print('-' * 30)\n",
    "        print('Saving predicted masks to files...')\n",
    "        print('-' * 30)\n",
    "        pred_dir = os.path.join(mask_data_path, 'test_fold'+str(fold))\n",
    "        if not os.path.exists(pred_dir):\n",
    "            os.mkdir(pred_dir)\n",
    "        for image, image_id in zip(imgs_mask_test, img_chunk):\n",
    "            f = gzip.GzipFile(os.path.join(pred_dir, image_id+\".npy.gz\"), \"w\")\n",
    "            np.save(file=f, arr=image)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
